/opt/ohpc/admin/lmod/lmod/init/bash: line 71: conda: command not found
/opt/ohpc/admin/lmod/lmod/init/bash: line 71: conda: command not found
Message from TWCC HPC admin
-----------------------
loading miniconda3 with conda 4.8.4/python 3.7
docs : https://hackmd.io/@kmo/twcc_hpc_conda
-----------------------

Namespace(batch_size=8, data_path='../data', debug=False, decay_factor=0.1, decay_step=10, epochs=8, height=224, img_size=416, log_path='epoch_yolo_test_1', log_period=125, loss_weight=0.0001, lr=0.0001, model_name='yoloatt', multiscale_training=True, no_cuda=False, num_workers=8, obj_names='./coco.names', obj_path='./', save_period=1, see_grad=False, use_yolov3=False, weight='../weights/yoloatt_v3_2_w.pth', width=320)
Dataset : train, number : 10000
Dataset : val, number : 5000
Load Model from ../weights/yoloatt_v3_2_w.pth
117264 5000
Epoch: 1 / Batch: 125, Att Loss: 0.612, Obj Loss: 29.782 (process time: 0.316, left time: 00h52m00s)
val loss: attention: 0.5547854900360107, obj: 32.04867172241211
Epoch: 1 / Batch: 250, Att Loss: 0.509, Obj Loss: 29.312 (process time: 0.332, left time: 00h53m55s)
val loss: attention: 0.49920693039894104, obj: 31.173019409179688
Epoch: 1 / Batch: 375, Att Loss: 0.465, Obj Loss: 29.057 (process time: 0.253, left time: 00h40m39s)
val loss: attention: 0.4763786494731903, obj: 32.27503204345703
Epoch: 1 / Batch: 500, Att Loss: 0.446, Obj Loss: 28.969 (process time: 0.235, left time: 00h37m14s)
val loss: attention: 0.45160651206970215, obj: 32.12876510620117
Epoch: 1 / Batch: 625, Att Loss: 0.429, Obj Loss: 28.985 (process time: 0.309, left time: 00h48m12s)
val loss: attention: 0.4190264642238617, obj: 30.850788116455078
Epoch: 1 / Batch: 750, Att Loss: 0.416, Obj Loss: 29.548 (process time: 0.317, left time: 00h48m48s)
val loss: attention: 0.4155777394771576, obj: 30.696720123291016
Epoch: 1 / Batch: 875, Att Loss: 0.407, Obj Loss: 29.234 (process time: 0.255, left time: 00h38m46s)
val loss: attention: 0.43653246760368347, obj: 30.51302146911621
Epoch: 1 / Batch: 1000, Att Loss: 0.400, Obj Loss: 28.758 (process time: 0.222, left time: 00h33m16s)
val loss: attention: 0.4317905604839325, obj: 30.531635284423828
Epoch: 1 / Batch: 1125, Att Loss: 0.387, Obj Loss: 29.330 (process time: 0.343, left time: 00h50m47s)
val loss: attention: 0.4143340587615967, obj: 32.236572265625
saving epoch_yolo_test_1/yoloatt/model/weight_1
Epoch: 2 / Batch: 125, Att Loss: 0.380, Obj Loss: 29.336 (process time: 0.239, left time: 00h34m19s)
val loss: attention: 0.3935612738132477, obj: 31.521728515625
Epoch: 2 / Batch: 250, Att Loss: 0.372, Obj Loss: 29.158 (process time: 0.237, left time: 00h33m31s)
val loss: attention: 0.384250283241272, obj: 34.003807067871094
Epoch: 2 / Batch: 375, Att Loss: 0.365, Obj Loss: 28.735 (process time: 0.249, left time: 00h34m49s)
val loss: attention: 0.37748807668685913, obj: 30.939380645751953
Epoch: 2 / Batch: 500, Att Loss: 0.361, Obj Loss: 28.746 (process time: 0.251, left time: 00h34m29s)
val loss: attention: 0.37184733152389526, obj: 30.8773136138916
Epoch: 2 / Batch: 625, Att Loss: 0.358, Obj Loss: 29.211 (process time: 0.252, left time: 00h34m09s)
val loss: attention: 0.37361106276512146, obj: 33.430965423583984
Epoch: 2 / Batch: 750, Att Loss: 0.358, Obj Loss: 29.059 (process time: 0.318, left time: 00h42m22s)
val loss: attention: 0.37650442123413086, obj: 30.359603881835938
Epoch: 2 / Batch: 875, Att Loss: 0.352, Obj Loss: 28.847 (process time: 0.236, left time: 00h30m57s)
val loss: attention: 0.36984512209892273, obj: 30.13823890686035
Epoch: 2 / Batch: 1000, Att Loss: 0.343, Obj Loss: 29.237 (process time: 0.231, left time: 00h29m47s)
val loss: attention: 0.37148189544677734, obj: 29.379993438720703
Epoch: 2 / Batch: 1125, Att Loss: 0.341, Obj Loss: 28.875 (process time: 0.249, left time: 00h31m37s)
val loss: attention: 0.36730867624282837, obj: 30.947010040283203
saving epoch_yolo_test_1/yoloatt/model/weight_2
Epoch: 3 / Batch: 125, Att Loss: 0.338, Obj Loss: 28.843 (process time: 0.249, left time: 00h30m38s)
val loss: attention: 0.37646451592445374, obj: 33.13299560546875
Epoch: 3 / Batch: 250, Att Loss: 0.338, Obj Loss: 28.582 (process time: 0.275, left time: 00h33m10s)
val loss: attention: 0.3749693036079407, obj: 33.46887969970703
Epoch: 3 / Batch: 375, Att Loss: 0.338, Obj Loss: 28.327 (process time: 0.277, left time: 00h32m54s)
val loss: attention: 0.354354590177536, obj: 30.186492919921875
Epoch: 3 / Batch: 500, Att Loss: 0.329, Obj Loss: 28.516 (process time: 0.258, left time: 00h30m05s)
val loss: attention: 0.3641161620616913, obj: 32.710853576660156
Epoch: 3 / Batch: 625, Att Loss: 0.335, Obj Loss: 28.330 (process time: 0.268, left time: 00h30m43s)
val loss: attention: 0.35366007685661316, obj: 30.237207412719727
Epoch: 3 / Batch: 750, Att Loss: 0.331, Obj Loss: 28.337 (process time: 0.232, left time: 00h26m08s)
val loss: attention: 0.3439021408557892, obj: 30.801513671875
Epoch: 3 / Batch: 875, Att Loss: 0.330, Obj Loss: 28.249 (process time: 0.266, left time: 00h29m22s)
val loss: attention: 0.3475807011127472, obj: 28.860248565673828
Epoch: 3 / Batch: 1000, Att Loss: 0.327, Obj Loss: 28.008 (process time: 0.283, left time: 00h30m36s)
val loss: attention: 0.35819709300994873, obj: 31.60837745666504
Epoch: 3 / Batch: 1125, Att Loss: 0.328, Obj Loss: 27.781 (process time: 0.217, left time: 00h23m02s)
val loss: attention: 0.3569544851779938, obj: 28.077756881713867
saving epoch_yolo_test_1/yoloatt/model/weight_3
Epoch: 4 / Batch: 125, Att Loss: 0.327, Obj Loss: 28.866 (process time: 0.292, left time: 00h29m47s)
val loss: attention: 0.3580043613910675, obj: 32.107521057128906
Epoch: 4 / Batch: 250, Att Loss: 0.321, Obj Loss: 27.951 (process time: 0.282, left time: 00h28m11s)
val loss: attention: 0.3529840409755707, obj: 29.428394317626953
Epoch: 4 / Batch: 375, Att Loss: 0.319, Obj Loss: 27.732 (process time: 0.270, left time: 00h26m25s)
val loss: attention: 0.3761332631111145, obj: 32.23581314086914
Epoch: 4 / Batch: 500, Att Loss: 0.318, Obj Loss: 28.041 (process time: 0.324, left time: 00h31m00s)
val loss: attention: 0.3490554690361023, obj: 28.955957412719727
Epoch: 4 / Batch: 625, Att Loss: 0.321, Obj Loss: 27.813 (process time: 0.243, left time: 00h22m47s)
val loss: attention: 0.33998382091522217, obj: 28.30134391784668
Epoch: 4 / Batch: 750, Att Loss: 0.320, Obj Loss: 28.206 (process time: 0.256, left time: 00h23m26s)
val loss: attention: 0.34860360622406006, obj: 32.72109603881836
Epoch: 4 / Batch: 875, Att Loss: 0.320, Obj Loss: 28.500 (process time: 0.288, left time: 00h25m48s)
val loss: attention: 0.3233332931995392, obj: 28.968862533569336
Epoch: 4 / Batch: 1000, Att Loss: 0.317, Obj Loss: 28.042 (process time: 0.240, left time: 00h21m01s)
val loss: attention: 0.3471764624118805, obj: 30.518115997314453
Epoch: 4 / Batch: 1125, Att Loss: 0.324, Obj Loss: 28.041 (process time: 0.301, left time: 00h25m42s)
val loss: attention: 0.33533617854118347, obj: 28.755903244018555
saving epoch_yolo_test_1/yoloatt/model/weight_4
Epoch: 5 / Batch: 125, Att Loss: 0.316, Obj Loss: 27.721 (process time: 0.223, left time: 00h18m05s)
val loss: attention: 0.3315260112285614, obj: 31.95118522644043
Epoch: 5 / Batch: 250, Att Loss: 0.316, Obj Loss: 27.788 (process time: 0.236, left time: 00h18m42s)
val loss: attention: 0.34057456254959106, obj: 37.23586654663086
Epoch: 5 / Batch: 375, Att Loss: 0.310, Obj Loss: 27.470 (process time: 0.277, left time: 00h21m20s)
val loss: attention: 0.3337736129760742, obj: 30.06349754333496
Epoch: 5 / Batch: 500, Att Loss: 0.316, Obj Loss: 27.965 (process time: 0.286, left time: 00h21m26s)
val loss: attention: 0.35340219736099243, obj: 35.91138458251953
Epoch: 5 / Batch: 625, Att Loss: 0.318, Obj Loss: 27.723 (process time: 0.236, left time: 00h17m14s)
val loss: attention: 0.33201971650123596, obj: 27.71514320373535
Epoch: 5 / Batch: 750, Att Loss: 0.317, Obj Loss: 27.784 (process time: 0.241, left time: 00h17m05s)
val loss: attention: 0.31837424635887146, obj: 29.416147232055664
Epoch: 5 / Batch: 875, Att Loss: 0.312, Obj Loss: 27.258 (process time: 0.238, left time: 00h16m23s)
val loss: attention: 0.3461691439151764, obj: 28.805753707885742
Epoch: 5 / Batch: 1000, Att Loss: 0.314, Obj Loss: 27.538 (process time: 0.311, left time: 00h20m45s)
val loss: attention: 0.3272564709186554, obj: 29.27328872680664
Epoch: 5 / Batch: 1125, Att Loss: 0.309, Obj Loss: 27.350 (process time: 0.288, left time: 00h18m35s)
val loss: attention: 0.3551096022129059, obj: 28.878768920898438
saving epoch_yolo_test_1/yoloatt/model/weight_5
Epoch: 6 / Batch: 125, Att Loss: 0.310, Obj Loss: 27.614 (process time: 0.247, left time: 00h14m53s)
val loss: attention: 0.3242304027080536, obj: 28.58555030822754
Epoch: 6 / Batch: 250, Att Loss: 0.310, Obj Loss: 27.165 (process time: 0.255, left time: 00h14m52s)
val loss: attention: 0.3367488384246826, obj: 28.432788848876953
Epoch: 6 / Batch: 375, Att Loss: 0.312, Obj Loss: 27.912 (process time: 0.284, left time: 00h16m00s)
val loss: attention: 0.3407926857471466, obj: 30.647790908813477
Epoch: 6 / Batch: 500, Att Loss: 0.311, Obj Loss: 27.412 (process time: 0.289, left time: 00h15m38s)
val loss: attention: 0.31964579224586487, obj: 29.273096084594727
Epoch: 6 / Batch: 625, Att Loss: 0.307, Obj Loss: 27.292 (process time: 0.296, left time: 00h15m26s)
val loss: attention: 0.34241095185279846, obj: 31.410741806030273
Epoch: 6 / Batch: 750, Att Loss: 0.317, Obj Loss: 27.374 (process time: 0.264, left time: 00h13m10s)
val loss: attention: 0.32893046736717224, obj: 27.7706356048584
Epoch: 6 / Batch: 875, Att Loss: 0.308, Obj Loss: 27.510 (process time: 0.227, left time: 00h10m51s)
val loss: attention: 0.3475101590156555, obj: 32.46657180786133
Epoch: 6 / Batch: 1000, Att Loss: 0.309, Obj Loss: 26.783 (process time: 0.281, left time: 00h12m53s)
val loss: attention: 0.30519431829452515, obj: 31.6661319732666
Epoch: 6 / Batch: 1125, Att Loss: 0.307, Obj Loss: 27.264 (process time: 0.289, left time: 00h12m38s)
val loss: attention: 0.32473936676979065, obj: 29.378372192382812
saving epoch_yolo_test_1/yoloatt/model/weight_6
Epoch: 7 / Batch: 125, Att Loss: 0.308, Obj Loss: 27.293 (process time: 0.335, left time: 00h13m15s)
val loss: attention: 0.34140923619270325, obj: 30.2623233795166
Epoch: 7 / Batch: 250, Att Loss: 0.306, Obj Loss: 27.007 (process time: 0.303, left time: 00h11m22s)
val loss: attention: 0.34110453724861145, obj: 32.18301773071289
Epoch: 7 / Batch: 375, Att Loss: 0.307, Obj Loss: 27.001 (process time: 0.276, left time: 00h09m45s)
val loss: attention: 0.3396209180355072, obj: 27.17612648010254
Epoch: 7 / Batch: 500, Att Loss: 0.305, Obj Loss: 27.038 (process time: 0.290, left time: 00h09m40s)
val loss: attention: 0.33362433314323425, obj: 29.022775650024414
Epoch: 7 / Batch: 625, Att Loss: 0.307, Obj Loss: 27.093 (process time: 0.287, left time: 00h08m57s)
val loss: attention: 0.35141420364379883, obj: 30.522541046142578
Epoch: 7 / Batch: 750, Att Loss: 0.307, Obj Loss: 26.842 (process time: 0.299, left time: 00h08m44s)
val loss: attention: 0.33502230048179626, obj: 28.4028377532959
Epoch: 7 / Batch: 875, Att Loss: 0.309, Obj Loss: 26.737 (process time: 0.319, left time: 00h08m38s)
val loss: attention: 0.3198586702346802, obj: 33.49733352661133
Epoch: 7 / Batch: 1000, Att Loss: 0.304, Obj Loss: 26.710 (process time: 0.246, left time: 00h06m09s)
val loss: attention: 0.32722821831703186, obj: 28.838306427001953
Epoch: 7 / Batch: 1125, Att Loss: 0.306, Obj Loss: 26.572 (process time: 0.303, left time: 00h06m57s)
val loss: attention: 0.34910663962364197, obj: 27.941858291625977
saving epoch_yolo_test_1/yoloatt/model/weight_7
Epoch: 8 / Batch: 125, Att Loss: 0.310, Obj Loss: 26.818 (process time: 0.266, left time: 00h04m59s)
val loss: attention: 0.33902284502983093, obj: 28.354110717773438
Epoch: 8 / Batch: 250, Att Loss: 0.300, Obj Loss: 27.007 (process time: 0.273, left time: 00h04m33s)
val loss: attention: 0.3422195613384247, obj: 31.02644157409668
Epoch: 8 / Batch: 375, Att Loss: 0.299, Obj Loss: 26.441 (process time: 0.267, left time: 00h03m53s)
val loss: attention: 0.33780983090400696, obj: 29.42056655883789
Epoch: 8 / Batch: 500, Att Loss: 0.304, Obj Loss: 26.548 (process time: 0.296, left time: 00h03m42s)
val loss: attention: 0.3332812786102295, obj: 28.561613082885742
Epoch: 8 / Batch: 625, Att Loss: 0.304, Obj Loss: 26.370 (process time: 0.299, left time: 00h03m06s)
val loss: attention: 0.31235119700431824, obj: 28.299808502197266
Epoch: 8 / Batch: 750, Att Loss: 0.303, Obj Loss: 26.385 (process time: 0.292, left time: 00h02m25s)
val loss: attention: 0.3329993188381195, obj: 27.797819137573242
Epoch: 8 / Batch: 875, Att Loss: 0.302, Obj Loss: 26.646 (process time: 0.293, left time: 00h01m49s)
val loss: attention: 0.3415221869945526, obj: 26.899723052978516
Epoch: 8 / Batch: 1000, Att Loss: 0.299, Obj Loss: 26.355 (process time: 0.214, left time: 00h00m53s)
val loss: attention: 0.33779439330101013, obj: 28.694101333618164
Epoch: 8 / Batch: 1125, Att Loss: 0.305, Obj Loss: 26.868 (process time: 0.318, left time: 00h00m39s)
val loss: attention: 0.3143855035305023, obj: 28.0696964263916
saving epoch_yolo_test_1/yoloatt/model/weight_8
saving epoch_yolo_test_1/yoloatt/model/weight_8
Finish
